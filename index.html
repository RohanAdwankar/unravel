<!DOCTYPE html>
<html>
<head>
    <title>unravel</title>
    <script type="module">
        import * as webllm from "https://esm.run/@mlc-ai/web-llm";
        const display = document.getElementById("output");
        const input = document.getElementById("input");
        const button = document.getElementById("send");
        let engine;

        async function init() {
            try {
                display.innerText = "Initializing engine...";
                engine = await webllm.CreateMLCEngine("Llama-3.2-1B-Instruct-q4f16_1-MLC", { 
                    initProgressCallback: (p) => display.innerText = p.text 
                });
                display.innerText = "Llama 3.2 Ready!";
                button.disabled = false;
            } catch (e) {
                display.innerText = "Error: " + e.message;
            }
        }

        button.onclick = async () => {
            button.disabled = true;
            const chunks = await engine.chat.completions.create({
                messages: [{ role: "user", content: input.value }],
                stream: true
            });
            let reply = "";
            for await (const chunk of chunks) {
                reply += chunk.choices[0]?.delta?.content || "";
                display.innerText = reply;
            }
            button.disabled = false;
        };
        init();
    </script>
</head>
<body>
    <div id="output">Initializing WebGPU...</div>
    <input type="text" id="input" placeholder="Ask Llama...">
    <button id="send" disabled>Send</button>
</body>
</html>
